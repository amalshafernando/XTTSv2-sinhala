{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sinhala XTTS-v2 Fine-tuning - Corrected Notebook\n",
    "## üá±üá∞ Complete End-to-End Pipeline with Dataset Column Mapping\n",
    "\n",
    "**Corrected for:**\n",
    "- Dataset: https://www.kaggle.com/datasets/amalshaf/sinhala-tts-dataset\n",
    "- CSV format: `audio_file_path | transcript | speaker_id`\n",
    "- Repository: https://github.com/amalshafernando/XTTSv2-sinhala (sinhala-tokenization branch)\n",
    "\n",
    "**This notebook will:**\n",
    "1. ‚úÖ Clone your repository\n",
    "2. ‚úÖ Mount and validate dataset\n",
    "3. ‚úÖ Prepare dataset with correct column mapping\n",
    "4. ‚úÖ Download XTTS-v2 model\n",
    "5. ‚úÖ Extend vocabulary (15,000 Sinhala tokens)\n",
    "6. ‚úÖ Fine-tune GPT for Sinhala\n",
    "7. ‚úÖ Generate sample speech\n",
    "\n",
    "**Time:** ~5-9 hours (mostly training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 1: Setup & Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PHASE 1: ENVIRONMENT SETUP\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nüì¶ Installing PyTorch with CUDA support...\")\n",
    "!pip install -q torch==2.1.0 torchaudio==2.1.0 --index-url https://download.pytorch.org/whl/cu118\n",
    "\n",
    "print(\"üì¶ Installing TTS framework...\")\n",
    "!pip install -q TTS>=0.22.0 transformers>=4.30.0 tokenizers>=0.13.0\n",
    "\n",
    "print(\"üì¶ Installing dependencies...\")\n",
    "!pip install -q pandas numpy tqdm pyyaml regex\n",
    "\n",
    "print(\"\\n‚úÖ Verifying installation...\")\n",
    "import torch\n",
    "import torchaudio\n",
    "from TTS.utils.manage import ModelManager\n",
    "\n",
    "print(f\"\\nPyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úÖ PHASE 1 COMPLETE\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 2: Clone Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PHASE 2: CLONE REPOSITORY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "repo_url = \"https://github.com/amalshafernando/XTTSv2-sinhala.git\"\n",
    "branch = \"sinhala-tokenization\"\n",
    "repo_path = \"/kaggle/working/XTTSv2-sinhala\"\n",
    "\n",
    "print(f\"\\nüì• Cloning repository...\")\n",
    "print(f\"   URL: {repo_url}\")\n",
    "print(f\"   Branch: {branch}\")\n",
    "\n",
    "if not os.path.exists(repo_path):\n",
    "    result = subprocess.run([\n",
    "        \"git\", \"clone\",\n",
    "        \"-b\", branch,\n",
    "        repo_url,\n",
    "        repo_path\n",
    "    ], capture_output=True, text=True)\n",
    "    \n",
    "    if result.returncode == 0:\n",
    "        print(f\"‚úÖ Repository cloned successfully\")\n",
    "    else:\n",
    "        print(f\"‚ùå Clone failed: {result.stderr}\")\n",
    "        raise RuntimeError(\"Failed to clone repository\")\n",
    "else:\n",
    "    print(f\"‚úÖ Repository already exists\")\n",
    "\n",
    "# Verify scripts\n",
    "print(f\"\\nüìã Verifying scripts...\")\n",
    "scripts = [\n",
    "    'extend_vocab_sinhala.py',\n",
    "    'train_gpt_xtts.py',\n",
    "    'config_sinhala.py',\n",
    "    'prepare_dataset_sinhala.py',\n",
    "    'inference_sinhala.py'\n",
    "]\n",
    "\n",
    "for script in scripts:\n",
    "    script_path = os.path.join(repo_path, script)\n",
    "    if os.path.exists(script_path):\n",
    "        size_kb = os.path.getsize(script_path) / 1024\n",
    "        print(f\"   ‚úÖ {script} ({size_kb:.1f} KB)\")\n",
    "    else:\n",
    "        print(f\"   ‚ö†Ô∏è  {script} not found\")\n",
    "\n",
    "# Add to path\n",
    "sys.path.insert(0, repo_path)\n",
    "\n",
    "print(f\"\\n\" + \"=\"*80)\n",
    "print(f\"‚úÖ PHASE 2 COMPLETE\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 3: Setup Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PHASE 3: SETUP CONFIGURATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Paths\n",
    "DATASET_INPUT = \"/kaggle/input/sinhala-tts-dataset\"\n",
    "WORKING_DIR = \"/kaggle/working\"\n",
    "DATASET_PROCESSED = os.path.join(WORKING_DIR, \"datasets\")\n",
    "CHECKPOINTS_DIR = os.path.join(WORKING_DIR, \"checkpoints\")\n",
    "XTTS_MODEL_DIR = os.path.join(CHECKPOINTS_DIR, \"XTTS_v2.0_original_model_files\")\n",
    "OUTPUT_DIR = os.path.join(WORKING_DIR, \"output\")\n",
    "\n",
    "# Create directories\n",
    "print(f\"\\nüìÅ Creating directories...\")\n",
    "for dir_path in [DATASET_PROCESSED, CHECKPOINTS_DIR, XTTS_MODEL_DIR, OUTPUT_DIR]:\n",
    "    os.makedirs(dir_path, exist_ok=True)\n",
    "\n",
    "# Configuration\n",
    "LANGUAGE_CODE = \"si\"\n",
    "VOCAB_SIZE = 15000\n",
    "NUM_EPOCHS = 5\n",
    "BATCH_SIZE = 8\n",
    "GRAD_ACCUM = 4\n",
    "LEARNING_RATE = 5e-6\n",
    "SAVE_STEP = 50000\n",
    "\n",
    "print(\"\\nüìã Configuration:\")\n",
    "print(f\"   Language: {LANGUAGE_CODE} (Sinhala)\")\n",
    "print(f\"   Vocab size: {VOCAB_SIZE:,} tokens\")\n",
    "print(f\"   Epochs: {NUM_EPOCHS}\")\n",
    "print(f\"   Batch size: {BATCH_SIZE}\")\n",
    "print(f\"   Learning rate: {LEARNING_RATE}\")\n",
    "\n",
    "print(f\"\\n\" + \"=\"*80)\n",
    "print(f\"‚úÖ PHASE 3 COMPLETE\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 4: Validate Dataset (CORRECTED FOR YOUR CSV FORMAT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PHASE 4: VALIDATE DATASET\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\n[1/4] Checking dataset at {DATASET_INPUT}\")\n",
    "if not os.path.exists(DATASET_INPUT):\n",
    "    print(f\"‚ùå Dataset not found!\")\n",
    "    raise FileNotFoundError(f\"Dataset path not found: {DATASET_INPUT}\")\n",
    "\n",
    "print(f\"‚úÖ Dataset found\")\n",
    "\n",
    "# List contents\n",
    "print(f\"\\n[2/4] Dataset contents:\")\n",
    "for item in os.listdir(DATASET_INPUT):\n",
    "    item_path = os.path.join(DATASET_INPUT, item)\n",
    "    if os.path.isdir(item_path):\n",
    "        count = len(os.listdir(item_path))\n",
    "        print(f\"   üìÅ {item}/ ({count} items)\")\n",
    "    else:\n",
    "        print(f\"   üìÑ {item}\")\n",
    "\n",
    "# Find CSV files\n",
    "print(f\"\\n[3/4] Validating CSV files:\")\n",
    "train_csv = None\n",
    "eval_csv = None\n",
    "\n",
    "# Look for standard filenames\n",
    "for fname in os.listdir(DATASET_INPUT):\n",
    "    if 'train' in fname.lower() and fname.endswith('.csv'):\n",
    "        train_csv = os.path.join(DATASET_INPUT, fname)\n",
    "    elif 'eval' in fname.lower() or 'val' in fname.lower() and fname.endswith('.csv'):\n",
    "        eval_csv = os.path.join(DATASET_INPUT, fname)\n",
    "    elif 'test' in fname.lower() and fname.endswith('.csv'):\n",
    "        eval_csv = os.path.join(DATASET_INPUT, fname)\n",
    "\n",
    "if train_csv and eval_csv:\n",
    "    print(f\"   ‚úÖ Found train: {os.path.basename(train_csv)}\")\n",
    "    print(f\"   ‚úÖ Found eval: {os.path.basename(eval_csv)}\")\n",
    "    \n",
    "    # Validate CSV format\n",
    "    print(f\"\\n[4/4] Validating CSV format:\")\n",
    "    \n",
    "    try:\n",
    "        df_train = pd.read_csv(train_csv, sep=',')\n",
    "        df_eval = pd.read_csv(eval_csv, sep=',')\n",
    "        \n",
    "        print(f\"   Train CSV columns: {list(df_train.columns)}\")\n",
    "        print(f\"   Train CSV rows: {len(df_train)}\")\n",
    "        print(f\"   Eval CSV rows: {len(df_eval)}\")\n",
    "        \n",
    "        # Check for expected columns (with flexible matching)\n",
    "        train_cols = [c.lower().strip() for c in df_train.columns]\n",
    "        print(f\"\\n   Column mapping:\")\n",
    "        \n",
    "        if 'audio_file_path' in train_cols:\n",
    "            print(f\"   ‚úÖ audio_file_path column found\")\n",
    "        if 'transcript' in train_cols:\n",
    "            print(f\"   ‚úÖ transcript column found\")\n",
    "        if 'speaker_id' in train_cols:\n",
    "            print(f\"   ‚úÖ speaker_id column found\")\n",
    "        \n",
    "        print(f\"\\n   Sample row:\")\n",
    "        print(f\"   {df_train.iloc[0].to_dict()}\")\n",
    "        \n",
    "        print(f\"\\n‚úÖ Dataset validation PASSED\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå Error reading CSV: {str(e)}\")\n",
    "        raise\n",
    "else:\n",
    "    print(f\"   ‚ùå Could not find train/eval CSV files\")\n",
    "    print(f\"   Please ensure dataset has train and eval CSV files\")\n",
    "    raise FileNotFoundError(\"CSV files not found\")\n",
    "\n",
    "print(f\"\\n\" + \"=\"*80)\n",
    "print(f\"‚úÖ PHASE 4 COMPLETE\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 5: Download XTTS-v2 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TTS.utils.manage import ModelManager\n",
    "import os\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PHASE 5: DOWNLOAD XTTS-v2 MODEL\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "files_to_download = [\n",
    "    (\"https://coqui.gateway.scarf.sh/hf-coqui/XTTS-v2/main/mel_stats.pth\", \"mel_stats.pth\"),\n",
    "    (\"https://coqui.gateway.scarf.sh/hf-coqui/XTTS-v2/main/dvae.pth\", \"dvae.pth\"),\n",
    "    (\"https://coqui.gateway.scarf.sh/hf-coqui/XTTS-v2/main/vocab.json\", \"vocab.json\"),\n",
    "    (\"https://coqui.gateway.scarf.sh/hf-coqui/XTTS-v2/main/model.pth\", \"model.pth\"),\n",
    "    (\"https://coqui.gateway.scarf.sh/hf-coqui/XTTS-v2/main/config.json\", \"config.json\"),\n",
    "    (\"https://coqui.gateway.scarf.sh/hf-coqui/XTTS-v2/main/speakers_xtts.pth\", \"speakers_xtts.pth\"),\n",
    "]\n",
    "\n",
    "print(f\"\\nDownloading {len(files_to_download)} model files...\")\n",
    "\n",
    "for idx, (url, filename) in enumerate(files_to_download, 1):\n",
    "    filepath = os.path.join(XTTS_MODEL_DIR, filename)\n",
    "    \n",
    "    if os.path.exists(filepath):\n",
    "        size_mb = os.path.getsize(filepath) / (1024 * 1024)\n",
    "        print(f\"[{idx}/{len(files_to_download)}] ‚úÖ {filename} ({size_mb:.1f} MB)\")\n",
    "    else:\n",
    "        print(f\"[{idx}/{len(files_to_download)}] üì• Downloading {filename}...\")\n",
    "        try:\n",
    "            ModelManager._download_model_files([url], XTTS_MODEL_DIR, progress_bar=True)\n",
    "            size_mb = os.path.getsize(filepath) / (1024 * 1024)\n",
    "            print(f\"       ‚úÖ Done ({size_mb:.1f} MB)\")\n",
    "        except Exception as e:\n",
    "            print(f\"       ‚ö†Ô∏è  Error: {str(e)}\")\n",
    "\n",
    "print(f\"\\n\" + \"=\"*80)\n",
    "print(f\"‚úÖ PHASE 5 COMPLETE\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 6: Prepare Dataset with Column Mapping (CORRECTED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import shutil\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PHASE 6: PREPARE DATASET WITH CORRECT COLUMN MAPPING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nDataset format: audio_file_path | transcript | speaker_id\")\n",
    "print(f\"Output format: audio_file | text | speaker_name\")\n",
    "\n",
    "# Read CSVs\n",
    "print(f\"\\n[1/3] Reading CSV files...\")\n",
    "df_train = pd.read_csv(train_csv, sep=',')\n",
    "df_eval = pd.read_csv(eval_csv, sep=',')\n",
    "\n",
    "print(f\"   Train: {len(df_train)} samples\")\n",
    "print(f\"   Eval: {len(df_eval)} samples\")\n",
    "\n",
    "# Create output directories\n",
    "print(f\"\\n[2/3] Creating output structure...\")\n",
    "wavs_dir = os.path.join(DATASET_PROCESSED, \"wavs\")\n",
    "os.makedirs(wavs_dir, exist_ok=True)\n",
    "\n",
    "# Copy audio files and create metadata\n",
    "print(f\"\\n[3/3] Processing data...\")\n",
    "\n",
    "def process_dataset(df, split_name):\n",
    "    \"\"\"Process dataset with column mapping\"\"\"\n",
    "    metadata = []\n",
    "    audio_source_dir = os.path.join(DATASET_INPUT, \"wavs\")\n",
    "    \n",
    "    if not os.path.exists(audio_source_dir):\n",
    "        print(f\"   ‚ö†Ô∏è  Audio directory not found: {audio_source_dir}\")\n",
    "        print(f\"   Looking in dataset input...\")\n",
    "        # Try to find wavs directory\n",
    "        for root, dirs, files in os.walk(DATASET_INPUT):\n",
    "            if 'wavs' in dirs:\n",
    "                audio_source_dir = os.path.join(root, 'wavs')\n",
    "                print(f\"   Found at: {audio_source_dir}\")\n",
    "                break\n",
    "    \n",
    "    processed = 0\n",
    "    skipped = 0\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        try:\n",
    "            # Map columns\n",
    "            audio_file = str(row['audio_file_path']).strip()\n",
    "            text = str(row['transcript']).strip()\n",
    "            speaker = str(row['speaker_id']).strip()\n",
    "            \n",
    "            # Source audio path\n",
    "            src_audio = os.path.join(audio_source_dir, audio_file)\n",
    "            \n",
    "            if os.path.exists(src_audio):\n",
    "                # Copy to output\n",
    "                dst_audio = os.path.join(wavs_dir, os.path.basename(audio_file))\n",
    "                if not os.path.exists(dst_audio):\n",
    "                    shutil.copy(src_audio, dst_audio)\n",
    "                \n",
    "                # Create metadata entry\n",
    "                metadata.append({\n",
    "                    'audio_file': os.path.join('wavs', os.path.basename(audio_file)),\n",
    "                    'text': text,\n",
    "                    'speaker': speaker\n",
    "                })\n",
    "                processed += 1\n",
    "            else:\n",
    "                skipped += 1\n",
    "        except Exception as e:\n",
    "            print(f\"      Error processing row {idx}: {str(e)}\")\n",
    "            skipped += 1\n",
    "    \n",
    "    print(f\"   {split_name}: {processed} processed, {skipped} skipped\")\n",
    "    return metadata\n",
    "\n",
    "# Process train and eval\n",
    "train_metadata = process_dataset(df_train, \"Train\")\n",
    "eval_metadata = process_dataset(df_eval, \"Eval\")\n",
    "\n",
    "# Save metadata files\n",
    "print(f\"\\n   Saving metadata...\")\n",
    "train_meta_path = os.path.join(DATASET_PROCESSED, \"metadata_train.csv\")\n",
    "eval_meta_path = os.path.join(DATASET_PROCESSED, \"metadata_eval.csv\")\n",
    "\n",
    "df_train_out = pd.DataFrame(train_metadata)\n",
    "df_eval_out = pd.DataFrame(eval_metadata)\n",
    "\n",
    "# Save in pipe-delimited format (expected by training scripts)\n",
    "df_train_out.to_csv(train_meta_path, sep='|', header=False, index=False)\n",
    "df_eval_out.to_csv(eval_meta_path, sep='|', header=False, index=False)\n",
    "\n",
    "print(f\"   ‚úÖ metadata_train.csv: {len(train_metadata)} rows\")\n",
    "print(f\"   ‚úÖ metadata_eval.csv: {len(eval_metadata)} rows\")\n",
    "\n",
    "print(f\"\\n\" + \"=\"*80)\n",
    "print(f\"‚úÖ PHASE 6 COMPLETE\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 7: Extend Vocabulary (ByteLevel BPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PHASE 7: EXTEND VOCABULARY FOR SINHALA\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "vocab_script = os.path.join(repo_path, \"extend_vocab_sinhala.py\")\n",
    "train_metadata_path = train_meta_path\n",
    "\n",
    "print(f\"\\nüìù Extending vocabulary...\")\n",
    "print(f\"   Metadata: {train_metadata_path}\")\n",
    "print(f\"   Output: {XTTS_MODEL_DIR}\")\n",
    "print(f\"   Vocab size: {VOCAB_SIZE:,} tokens\")\n",
    "print(f\"   Method: ByteLevel BPE\")\n",
    "\n",
    "cmd = [\n",
    "    sys.executable,\n",
    "    vocab_script,\n",
    "    \"--metadata_path\", train_metadata_path,\n",
    "    \"--output_path\", XTTS_MODEL_DIR,\n",
    "    \"--language\", LANGUAGE_CODE,\n",
    "    \"--vocab_size\", str(VOCAB_SIZE)\n",
    "]\n",
    "\n",
    "print(f\"\\n[Running] Tokenization Training...\\n\")\n",
    "\n",
    "try:\n",
    "    result = subprocess.run(cmd, capture_output=True, text=True, timeout=1800)\n",
    "    print(result.stdout)\n",
    "    \n",
    "    if result.returncode != 0:\n",
    "        print(f\"‚ùå Error:\")\n",
    "        print(result.stderr)\n",
    "        raise RuntimeError(\"Vocabulary extension failed\")\n",
    "    else:\n",
    "        print(f\"‚úÖ Vocabulary extension SUCCESSFUL\")\n",
    "        \n",
    "except subprocess.TimeoutExpired:\n",
    "    print(f\"‚ùå Timeout - vocabulary extension took too long\")\n",
    "    raise\n",
    "\n",
    "print(f\"\\n\" + \"=\"*80)\n",
    "print(f\"‚úÖ PHASE 7 COMPLETE\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 8: GPT Fine-tuning (4-8 HOURS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PHASE 8: GPT FINE-TUNING (MAIN TRAINING - 4-8 HOURS)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "train_script = os.path.join(repo_path, \"train_gpt_xtts.py\")\n",
    "\n",
    "print(f\"\\nüöÄ Starting GPT Fine-tuning...\")\n",
    "print(f\"   Train data: {train_meta_path}\")\n",
    "print(f\"   Eval data: {eval_meta_path}\")\n",
    "print(f\"   Language: {LANGUAGE_CODE}\")\n",
    "print(f\"   Epochs: {NUM_EPOCHS}\")\n",
    "print(f\"   Batch size: {BATCH_SIZE}\")\n",
    "print(f\"\\n‚è±Ô∏è  This will take 4-8 hours...\")\n",
    "print(f\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "# Build metadata string\n",
    "metadata_string = f\"{train_meta_path},{eval_meta_path},{LANGUAGE_CODE}\"\n",
    "\n",
    "cmd = [\n",
    "    sys.executable,\n",
    "    train_script,\n",
    "    \"--output_path\", CHECKPOINTS_DIR,\n",
    "    \"--metadatas\", metadata_string,\n",
    "    \"--num_epochs\", str(NUM_EPOCHS),\n",
    "    \"--batch_size\", str(BATCH_SIZE),\n",
    "    \"--grad_acumm\", str(GRAD_ACCUM),\n",
    "    \"--max_text_length\", \"400\",\n",
    "    \"--max_audio_length\", \"330750\",\n",
    "    \"--lr\", str(LEARNING_RATE),\n",
    "    \"--weight_decay\", \"1e-2\",\n",
    "    \"--save_step\", str(SAVE_STEP)\n",
    "]\n",
    "\n",
    "try:\n",
    "    result = subprocess.run(cmd, text=True)\n",
    "    \n",
    "    if result.returncode == 0:\n",
    "        print(f\"\\n\" + \"=\"*80)\n",
    "        print(f\"‚úÖ TRAINING COMPLETED SUCCESSFULLY\")\n",
    "        print(\"=\"*80)\n",
    "    else:\n",
    "        print(f\"\\n‚ùå Training failed\")\n",
    "        \n",
    "except KeyboardInterrupt:\n",
    "    print(f\"\\n‚ö†Ô∏è  Training interrupted\")\n",
    "\n",
    "print(f\"\\n\" + \"=\"*80)\n",
    "print(f\"‚úÖ PHASE 8 COMPLETE\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 9: Generate Sample Speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "from TTS.tts.models.xtts import Xtts\n",
    "from TTS.tts.configs.xtts_config import XttsConfig\n",
    "import os\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PHASE 9: GENERATE SAMPLE SPEECH\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"\\nüì± Using device: {device}\")\n",
    "\n",
    "# Find checkpoint\n",
    "training_dir = os.path.join(CHECKPOINTS_DIR, \"run\", \"training\")\n",
    "config_path = os.path.join(XTTS_MODEL_DIR, \"config.json\")\n",
    "vocab_path = os.path.join(XTTS_MODEL_DIR, \"vocab.json\")\n",
    "\n",
    "print(f\"\\nüîß Loading model...\")\n",
    "\n",
    "if os.path.exists(training_dir):\n",
    "    checkpoints = [f for f in os.listdir(training_dir) if f.endswith('.pth')]\n",
    "    \n",
    "    if checkpoints and os.path.exists(config_path):\n",
    "        checkpoints.sort()\n",
    "        checkpoint_path = os.path.join(training_dir, checkpoints[-1])\n",
    "        print(f\"‚úÖ Found checkpoint: {checkpoints[-1]}\")\n",
    "        \n",
    "        try:\n",
    "            config = XttsConfig()\n",
    "            config.load_json(config_path)\n",
    "            \n",
    "            model = Xtts.init_from_config(config)\n",
    "            model.load_checkpoint(\n",
    "                config,\n",
    "                checkpoint_path=checkpoint_path,\n",
    "                vocab_path=vocab_path,\n",
    "                use_deepspeed=False\n",
    "            )\n",
    "            model.to(device)\n",
    "            \n",
    "            print(f\"‚úÖ Model loaded successfully!\")\n",
    "            \n",
    "            # Find reference audio\n",
    "            wavs_dir = os.path.join(DATASET_PROCESSED, \"wavs\")\n",
    "            audio_files = [f for f in os.listdir(wavs_dir) if f.endswith('.wav')] if os.path.exists(wavs_dir) else []\n",
    "            \n",
    "            if audio_files:\n",
    "                reference_audio = os.path.join(wavs_dir, audio_files[0])\n",
    "                print(f\"üé§ Reference audio: {audio_files[0]}\")\n",
    "                \n",
    "                # Test text\n",
    "                test_text = \"‡∂±‡∑í‡∂ª‡∂±‡∑ä‡∂≠‡∂ª‡∂∫‡∑í ‡∂â‡∂≠‡∑è ‡∑Ä‡∑ê‡∂Ø‡∂ú‡∂≠‡∑ä\"\n",
    "                print(f\"\\nüìù Test text: {test_text}\")\n",
    "                \n",
    "                try:\n",
    "                    print(f\"\\nüéµ Generating speech...\")\n",
    "                    \n",
    "                    # Get speaker embedding\n",
    "                    gpt_cond_latent, speaker_embedding = model.get_conditioning_latents(\n",
    "                        audio_path=reference_audio,\n",
    "                        gpt_cond_len=model.config.gpt_cond_len,\n",
    "                        max_ref_length=model.config.max_ref_len,\n",
    "                        sound_norm_refs=model.config.sound_norm_refs,\n",
    "                    )\n",
    "                    \n",
    "                    # Generate speech\n",
    "                    wav = model.inference(\n",
    "                        text=test_text,\n",
    "                        language=\"si\",\n",
    "                        gpt_cond_latent=gpt_cond_latent,\n",
    "                        speaker_embedding=speaker_embedding,\n",
    "                        temperature=0.7,\n",
    "                        length_penalty=1.0,\n",
    "                        repetition_penalty=5.0,\n",
    "                        top_k=50,\n",
    "                        top_p=0.85,\n",
    "                    )\n",
    "                    \n",
    "                    # Save audio\n",
    "                    output_file = os.path.join(OUTPUT_DIR, \"sinhala_sample.wav\")\n",
    "                    torchaudio.save(\n",
    "                        output_file,\n",
    "                        torch.tensor(wav[\"wav\"]).unsqueeze(0),\n",
    "                        24000\n",
    "                    )\n",
    "                    \n",
    "                    duration_sec = len(wav['wav']) / 24000\n",
    "                    print(f\"‚úÖ Speech generated!\")\n",
    "                    print(f\"   File: {output_file}\")\n",
    "                    print(f\"   Duration: {duration_sec:.2f} seconds\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"‚ùå Generation error: {str(e)}\")\n",
    "            else:\n",
    "                print(f\"‚ö†Ô∏è No audio files found for reference\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error loading model: {str(e)}\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è Checkpoint or config not found\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è Training directory not found\")\n",
    "    print(f\"   Make sure Phase 8 completed successfully\")\n",
    "\n",
    "print(f\"\\n\" + \"=\"*80)\n",
    "print(f\"‚úÖ PHASE 9 COMPLETE\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 10: Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\\n\" + \"#\"*80)\n",
    "print(\"#\" + \" \"*78 + \"#\")\n",
    "print(\"#\" + \" \"*15 + \"‚úÖ SINHALA XTTS-v2 FINE-TUNING COMPLETE!\" + \" \"*26 + \"#\")\n",
    "print(\"#\" + \" \"*78 + \"#\")\n",
    "print(\"#\"*80)\n",
    "\n",
    "print(\"\\n‚úÖ COMPLETED PHASES:\")\n",
    "phases = [\n",
    "    \"Environment Setup\",\n",
    "    \"Clone Repository\",\n",
    "    \"Setup Configuration\",\n",
    "    \"Validate Dataset\",\n",
    "    \"Download XTTS-v2 Model\",\n",
    "    \"Prepare Dataset with Column Mapping\",\n",
    "    \"Extend Vocabulary (15,000 Sinhala tokens)\",\n",
    "    \"Fine-tune GPT\",\n",
    "    \"Generate Sample Speech\"\n",
    "]\n",
    "\n",
    "for i, phase in enumerate(phases, 1):\n",
    "    print(f\"   {i}. ‚úÖ {phase}\")\n",
    "\n",
    "print(\"\\nüìä MODEL SPECIFICATIONS:\")\n",
    "print(f\"   Language: Sinhala (‡∑É‡∑í‡∂Ç‡∑Ñ‡∂Ω)\")\n",
    "print(f\"   Language Code: si\")\n",
    "print(f\"   Tokenization: ByteLevel BPE\")\n",
    "print(f\"   Vocabulary: 15,000 tokens\")\n",
    "print(f\"   Training Epochs: {NUM_EPOCHS}\")\n",
    "print(f\"   Batch Size: {BATCH_SIZE}\")\n",
    "print(f\"   Learning Rate: {LEARNING_RATE}\")\n",
    "\n",
    "print(\"\\nüìÅ OUTPUT FILES:\")\n",
    "print(f\"   Model Checkpoint: {os.path.join(CHECKPOINTS_DIR, 'run/training/')}\")\n",
    "print(f\"   Vocabulary: {os.path.join(XTTS_MODEL_DIR, 'vocab.json')}\")\n",
    "print(f\"   Config: {os.path.join(XTTS_MODEL_DIR, 'config.json')}\")\n",
    "print(f\"   Sample Output: {os.path.join(OUTPUT_DIR, 'sinhala_sample.wav')}\")\n",
    "\n",
    "print(\"\\nüéâ KEY FIXES IN THIS NOTEBOOK:\")\n",
    "print(f\"   ‚úÖ Corrected CSV column mapping\")\n",
    "print(f\"      From: audio_file_path | transcript | speaker_id\")\n",
    "print(f\"      To: audio_file | text | speaker_name\")\n",
    "print(f\"   ‚úÖ Automatic audio file discovery\")\n",
    "print(f\"   ‚úÖ Error handling for missing files\")\n",
    "print(f\"   ‚úÖ Proper metadata formatting\")\n",
    "\n",
    "print(\"\\n\" + \"#\"*80)\n",
    "print(\"#\" + \" \"*78 + \"#\")\n",
    "print(\"#\" + \" \"*18 + \"üéµ Your Sinhala TTS Model is Ready! üéµ\" + \" \"*22 + \"#\")\n",
    "print(\"#\" + \" \"*78 + \"#\")\n",
    "print(\"#\"*80 + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 8547335,
     "sourceId": 13465111,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31154,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
